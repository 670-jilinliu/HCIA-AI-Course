{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mindspore.nn as nn\n",
    "from mindspore import Tensor\n",
    "import mindspore.dataset as ds\n",
    "import mindspore as ms\n",
    "\n",
    "loss = nn.L1Loss()\n",
    "output_data = Tensor(np.array([[1, 2, 3], [2, 3, 4]]).astype(np.float32))\n",
    "target_data = Tensor(np.array([[0, 2, 5], [3, 1, 1]]).astype(np.float32))\n",
    "print(loss(output_data, target_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = nn.Momentum(params=modelle.trainable_params(), learning_rate=0.1, momentum=0.9, weight_decay=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型编译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import Model\n",
    "\n",
    "# 定义神经网络\n",
    "net = LeNet5()\n",
    "# 定义损失函数\n",
    "loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "# 定义优化器\n",
    "optim = nn.Momentum(params=net.trainable_params(), learning_rate=0.1, momentum=0.9)\n",
    "# 模型编译\n",
    "model = Model(net, loss_fn=loss, optimizer=optim, metrics={'accuracy'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.dataset.transforms.c_transforms as C\n",
    "import mindspore.dataset.vision.c_transforms as CV\n",
    "from mindspore.train.callback import LossMonitor\n",
    "\n",
    "DATA_DIR = \"./MNIST_Data/train\"\n",
    "mnist_dataset = ds.MnistDataset(DATA_DIR)\n",
    "\n",
    "resize_op = CV.Resize((28, 28))\n",
    "rescale_op = CV.Rescale(1 / 255, 0)\n",
    "hwc2chw_op = CV.HWC2CHW()\n",
    "\n",
    "mnist_dataset = mnist_dataset.map(input_columns=\"image\", operations=[rescale_op, resize_op, hwc2chw_op])\n",
    "mnist_dataset = mnist_dataset.map(input_columns=\"label\", operations=C.TypeCast(mstype.int32))\n",
    "mnist_dataset = mnist_dataset.batch(32)\n",
    "loss_cb = LossMonitor(per_print_times=1000)\n",
    "# dataset 是传入参数代表训练集，epoch是训练集迭代次数\n",
    "model.train(epoch=1, train_dataset=mnist_dataset, callbacks=[loss_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集\n",
    "DATA_DIR = \"./MNIST_Data/test\"\n",
    "dataset = ds.MnistDataset(DATA_DIR)\n",
    "\n",
    "resize_op = CV.Resize((28, 28))\n",
    "rescale_op = CV.Rescale(1 / 255, 0)\n",
    "hwc2chw_op = CV.HWC2CHW()\n",
    "\n",
    "dataset = dataset.map(input_columns=\"image\", operations=[rescale_op, resize_op, hwc2chw_op])\n",
    "dataset = dataset.map(input_columns=\"label\", operations=C.TypeCast(mstype.int32))\n",
    "dataset = dataset.batch(32)\n",
    "model.eval(val_dataset=dataset)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
