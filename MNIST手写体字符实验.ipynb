{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入 Python 库&模块并配置运行信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关依赖库\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import mindspore as ms\n",
    "import mindspore.context as context\n",
    "import mindspore.dataset as ds\n",
    "import mindspore.dataset.transforms.c_transforms as C\n",
    "import mindspore.dataset.vision.c_transforms as CV\n",
    "from mindspore.nn.metrics import Accuracy\n",
    "\n",
    "from mindspore import nn\n",
    "from mindspore.train import Model\n",
    "from mindspore.train.callback import (\n",
    "    ModelCheckpoint,\n",
    "    CheckpointConfig,\n",
    "    LossMonitor,\n",
    "    TimeMonitor,\n",
    ")\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_TRAIN = \"MNIST/train\"  # 训练集信息\n",
    "DATA_DIR_TEST = \"MNIST/test\"  # 测试集信息\n",
    "# 读取数据\n",
    "ds_train = ds.MnistDataset(DATA_DIR_TRAIN)\n",
    "ds_test = ds.MnistDataset(DATA_DIR_TEST)\n",
    "# 显示数据集的相关特性\n",
    "print(\"训练数据集数量：\", ds_train.get_dataset_size())\n",
    "print(\"测试数据集数量：\", ds_test.get_dataset_size())\n",
    "image = ds_train.create_dict_iterator().__next__()\n",
    "print(\"图像长/宽/通道数：\", image[\"image\"].shape)\n",
    "print(\"一张图像的标签样式：\", image[\"label\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(\n",
    "    training=True,\n",
    "    batch_size=128,\n",
    "    resize=(28, 28),\n",
    "    rescale=1 / 255,\n",
    "    shift=0,\n",
    "    buffer_size=64,\n",
    "):\n",
    "    ds = ms.dataset.MnistDataset(DATA_DIR_TRAIN if training else DATA_DIR_TEST)\n",
    "    # 定义 Map 操作尺寸缩放，归一化和通道变换\n",
    "    resize_op = CV.Resize(resize)\n",
    "    rescale_op = CV.Rescale(rescale, shift)\n",
    "    hwc2chw_op = CV.HWC2CHW()\n",
    "    # 对数据集进行 Map 操作\n",
    "    ds = ds.map(input_columns=\"image\", operations=[rescale_op, resize_op, hwc2chw_op])\n",
    "    ds = ds.map(input_columns=\"label\", operations=C.TypeCast(ms.int32))\n",
    "    # 设定打乱操作参数和 batchsize 大小\n",
    "    ds = ds.shuffle(buffer_size=buffer_size)\n",
    "    ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "样本可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示前10张图片以及对应标签，检查图片是否是正确的数据集\n",
    "ds = create_dataset(training=False)\n",
    "data = ds.create_dict_iterator().__next__()\n",
    "images = data[\"image\"].asnumpy()\n",
    "labels = data[\"label\"].asnumpy()\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(1, 11):\n",
    "    plt.subplot(2, 5, i)\n",
    "    plt.imshow(np.squeeze(images[i]))\n",
    "    plt.title(\"Number: %s\" % labels[i])\n",
    "    plt.xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型。模型包括3个全连接层，最后输出层使用softmax进行多分类，并分成 (0-9) 10类\n",
    "class ForwardNN(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(ForwardNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Dense(784, 512, activation=\"relu\")\n",
    "        self.fc2 = nn.Dense(512, 128, activation=\"relu\")\n",
    "        self.fc3 = nn.Dense(128, 10, activation=None)\n",
    "\n",
    "    def construct(self, input_x):\n",
    "        output = self.flatten(input_x)\n",
    "        output = self.fc1(output)\n",
    "        output = self.fc2(output)\n",
    "        output = self.fc3(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义损失函数及优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建网络，损失函数，评估指标，优化器，设定相关超参数\n",
    "lr = 0.001\n",
    "num_epochs = 10\n",
    "momentum = 0.9\n",
    "\n",
    "net = ForwardNN()\n",
    "loss = nn.loss.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\n",
    "metrics = {\"Accuracy\": Accuracy()}\n",
    "opt = nn.Adam(net.trainable_params(), lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编译模型\n",
    "model = Model(net, loss, opt, metrics)\n",
    "config_ck = CheckpointConfig(save_checkpoint_steps=1875, keep_checkpoint_max=10)\n",
    "ckpoint_cb = ModelCheckpoint(\n",
    "    prefix=\"checkpoint_net\", directory=\"./ckpt\", config=config_ck\n",
    ")\n",
    "# 生成数据集\n",
    "ds_eval = create_dataset(False, batch_size=32)\n",
    "ds_train = create_dataset(batch_size=32)\n",
    "# 训练模型\n",
    "loss_cb = LossMonitor(per_print_times=1875)\n",
    "time_cb = TimeMonitor(data_size=ds_train.get_dataset_size())\n",
    "print(\"============== Starting Training ==============\")\n",
    "model.train(\n",
    "    num_epochs,\n",
    "    ds_train,\n",
    "    callbacks=[time_cb, loss_cb, ckpoint_cb],\n",
    "    dataset_sink_mode=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用测试集评估模型，打印总体准确率\n",
    "metrics = model.eval(ds_eval)\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
