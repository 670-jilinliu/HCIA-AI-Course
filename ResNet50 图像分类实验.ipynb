{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入 Python 库&模块并配置运行信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict  # 字典访问，用来存储超参数\n",
    "import os  # os模块主要用于处理文件和目录\n",
    "import numpy as np  # 科学计算库\n",
    "import matplotlib.pyplot as plt  # 绘图库\n",
    "\n",
    "import mindspore  # mindspore框架\n",
    "import mindspore.dataset as ds  # 数据集处理模块\n",
    "from mindspore.dataset.vision import c_transforms as vision  # 图像增强模块\n",
    "from mindspore import context  # 环境设置模块\n",
    "import mindspore.nn as nn  # 神经网络模块\n",
    "from mindspore.train import Model  # 模型编译\n",
    "from mindspore.nn.optim.momentum import Momentum  # 动量优化器\n",
    "from mindspore.train.callback import (\n",
    "    ModelCheckpoint,\n",
    "    CheckpointConfig,\n",
    "    LossMonitor,\n",
    ")  # 模型保存设置\n",
    "from mindspore import Tensor  # 张量\n",
    "from mindspore.train.serialization import export  # 模型导出\n",
    "from mindspore.train.loss_scale_manager import FixedLossScaleManager  # 损失值平滑处理\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net  # 模型加载\n",
    "import mindspore.ops as ops  # 常见算子操作\n",
    "\n",
    "# 设置 MindSpore 的执行模式和设备\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义参数变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = edict(\n",
    "    {\n",
    "        \"data_path\": \"flower_photos_train\",  # 训练数据集路径\n",
    "        \"test_path\": \"flower_photos_test\",  # 测试数据集路径\n",
    "        \"data_size\": 3616,\n",
    "        \"HEIGHT\": 224,  # 图像高度\n",
    "        \"WIDTH\": 224,  # 图像宽度\n",
    "        \"_R_MEAN\": 123.68,  # CIFAR10的均值\n",
    "        \"_G_MEAN\": 116.78,\n",
    "        \"_B_MEAN\": 103.94,\n",
    "        \"_R_STD\": 1,  # 自定义的标准差\n",
    "        \"_G_STD\": 1,\n",
    "        \"_B_STD\": 1,\n",
    "        \"_RESIZE_SIDE_MIN\": 256,  # 图像增强resiz值\n",
    "        \"_RESIZE_SIDE_MAX\": 512,\n",
    "        \"batch_size\": 32,  # 批次大小\n",
    "        \"num_class\": 5,  # 分类数\n",
    "        \"epoch_size\": 10,  # 训练轮数\n",
    "        \"loss_scale_num\": 1024,\n",
    "        \"prefix\": \"resnet-ai\",  # 模型保存的名称\n",
    "        \"directory\": \"./model_resnet\",  # 模型保存的路径\n",
    "        \"save_checkpoint_steps\": 10,  # 每隔10步保存ckpt\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据的读取和处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理\n",
    "def read_data(path, config, usage=\"train\"):\n",
    "    # 从目录中读取图像的源数据集。\n",
    "    dataset = ds.ImageFolderDataset(\n",
    "        path,\n",
    "        class_indexing={\n",
    "            \"daisy\": 0,\n",
    "            \"dandelion\": 1,\n",
    "            \"roses\": 2,\n",
    "            \"sunflowers\": 3,\n",
    "            \"tulips\": 4,\n",
    "        },\n",
    "    )\n",
    "    # define map operations\n",
    "    # 图像解码算子\n",
    "    decode_op = vision.Decode()\n",
    "    # 图像正则化算子\n",
    "    normalize_op = vision.Normalize(\n",
    "        mean=[cfg._R_MEAN, cfg._G_MEAN, cfg._B_MEAN],\n",
    "        std=[cfg._R_STD, cfg._G_STD, cfg._B_STD],\n",
    "    )\n",
    "    # 图像调整大小算子\n",
    "    resize_op = vision.Resize(cfg._RESIZE_SIDE_MIN)\n",
    "    # 图像裁剪算子\n",
    "    center_crop_op = vision.CenterCrop((cfg.HEIGHT, cfg.WIDTH))\n",
    "    # 图像随机水平翻转算子\n",
    "    horizontal_flip_op = vision.RandomHorizontalFlip()\n",
    "    # 图像通道数转换算子\n",
    "    changeswap_op = vision.HWC2CHW()\n",
    "    # 图像随机裁剪解码调整大小算子\n",
    "    random_crop_decode_resize_op = vision.RandomCropDecodeResize(\n",
    "        (cfg.HEIGHT, cfg.WIDTH), (0.5, 1.0), (1.0, 1.0), max_attempts=100\n",
    "    )\n",
    "\n",
    "    # 只对训练集做的预处理操作\n",
    "    if usage == \"train\":\n",
    "        dataset = dataset.map(\n",
    "            input_columns=\"image\", operations=random_crop_decode_resize_op\n",
    "        )\n",
    "        dataset = dataset.map(input_columns=\"image\", operations=horizontal_flip_op)\n",
    "    # 只对测试集做的预处理操作\n",
    "    else:\n",
    "        dataset = dataset.map(input_columns=\"image\", operations=decode_op)\n",
    "        dataset = dataset.map(input_columns=\"image\", operations=resize_op)\n",
    "        dataset = dataset.map(input_columns=\"image\", operations=center_crop_op)\n",
    "\n",
    "    # 对全部数据做的预处理操作\n",
    "    dataset = dataset.map(input_columns=\"image\", operations=normalize_op)\n",
    "    dataset = dataset.map(input_columns=\"image\", operations=changeswap_op)\n",
    "\n",
    "    # 对训练集做的批次处理\n",
    "    if usage == \"train\":\n",
    "        dataset = dataset.shuffle(buffer_size=1000)  # 10000 as in imageNet train script\n",
    "        dataset = dataset.batch(cfg.batch_size, drop_remainder=True)\n",
    "    # 对测试集做的批次处理\n",
    "    else:\n",
    "        dataset = dataset.batch(1, drop_remainder=True)\n",
    "\n",
    "    # 数据增强\n",
    "    dataset = dataset.repeat(1)\n",
    "    dataset.map_model = 4\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# 查看训练集和测试集的数量\n",
    "de_train = read_data(cfg.data_path, cfg, usage=\"train\")\n",
    "de_test = read_data(cfg.test_path, cfg, usage=\"test\")\n",
    "print(\n",
    "    \"训练数据集数量：\", de_train.get_dataset_size() * cfg.batch_size\n",
    ")  # get_dataset_size()返回的是batch的数量\n",
    "print(\"测试数据集数量：\", de_test.get_dataset_size())\n",
    "\n",
    "# 查看训练集的样图\n",
    "data_next = de_train.create_dict_iterator(output_numpy=True).__next__()\n",
    "print(\"通道数/图像长/宽：\", data_next[\"image\"][0, ...].shape)\n",
    "print(\"一张图像的标签样式：\", data_next[\"label\"][0])  # 一共五类，用0-4表示\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(data_next[\"image\"][0, 0, ...])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型构建训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义权重初始化函数\n",
    "def _weight_variable(shape, factor=0.01):\n",
    "    init_value = np.random.randn(*shape).astype(np.float32) * factor\n",
    "    return Tensor(init_value)\n",
    "\n",
    "\n",
    "# 定义 3x3 卷积层\n",
    "def _conv3x3(in_channel, out_channel, stride=1):\n",
    "    weight_shape = (out_channel, in_channel, 3, 3)\n",
    "    weight = _weight_variable(weight_shape)\n",
    "    return nn.Conv2d(\n",
    "        in_channel,\n",
    "        out_channel,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=0,\n",
    "        pad_mode=\"same\",\n",
    "        weight_init=weight,\n",
    "    )\n",
    "\n",
    "\n",
    "# 定义 1x1 卷积层\n",
    "def _conv1x1(in_channel, out_channel, stride=1):\n",
    "    weight_shape = (out_channel, in_channel, 1, 1)\n",
    "    weight = _weight_variable(weight_shape)\n",
    "    return nn.Conv2d(\n",
    "        in_channel,\n",
    "        out_channel,\n",
    "        kernel_size=1,\n",
    "        stride=stride,\n",
    "        padding=0,\n",
    "        pad_mode=\"same\",\n",
    "        weight_init=weight,\n",
    "    )\n",
    "\n",
    "\n",
    "# 定义 7x7 卷积层\n",
    "def _conv7x7(in_channel, out_channel, stride=1):\n",
    "    weight_shape = (out_channel, in_channel, 7, 7)\n",
    "    weight = _weight_variable(weight_shape)\n",
    "    return nn.Conv2d(\n",
    "        in_channel,\n",
    "        out_channel,\n",
    "        kernel_size=7,\n",
    "        stride=stride,\n",
    "        padding=0,\n",
    "        pad_mode=\"same\",\n",
    "        weight_init=weight,\n",
    "    )\n",
    "\n",
    "\n",
    "# 定义 Batch Norm 层函数\n",
    "def _bn(channel):\n",
    "    return nn.BatchNorm2d(\n",
    "        channel,\n",
    "        eps=1e-4,\n",
    "        momentum=0.9,\n",
    "        gamma_init=1,\n",
    "        beta_init=0,\n",
    "        moving_mean_init=0,\n",
    "        moving_var_init=1,\n",
    "    )\n",
    "\n",
    "\n",
    "# 定义最后一层的 Batch Norm 层函数\n",
    "def _bn_last(channel):\n",
    "    return nn.BatchNorm2d(\n",
    "        channel,\n",
    "        eps=1e-4,\n",
    "        momentum=0.9,\n",
    "        gamma_init=0,\n",
    "        beta_init=0,\n",
    "        moving_mean_init=0,\n",
    "        moving_var_init=1,\n",
    "    )\n",
    "\n",
    "\n",
    "# 定义全连接层函数\n",
    "def _fc(in_channel, out_channel):\n",
    "    weight_shape = (out_channel, in_channel)\n",
    "    weight = _weight_variable(weight_shape)\n",
    "    return nn.Dense(\n",
    "        in_channel, out_channel, has_bias=True, weight_init=weight, bias_init=0\n",
    "    )\n",
    "\n",
    "\n",
    "# 构建残差模块\n",
    "class ResidualBlock(nn.Cell):\n",
    "    def __init__(self, in_channel, out_channel, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.expansion = 4\n",
    "        # 前两层的卷积核个数等于输出通道的四分之一\n",
    "        channel = out_channel // self.expansion\n",
    "\n",
    "        # 第一层卷积\n",
    "        self.conv1 = _conv1x1(in_channel, channel, stride=1)\n",
    "        self.bn1 = _bn(channel)\n",
    "        # 第二层卷积\n",
    "        self.conv2 = _conv3x3(channel, channel, stride=stride)\n",
    "        self.bn2 = _bn(channel)\n",
    "\n",
    "        # 第三层卷积\n",
    "        self.conv3 = _conv1x1(channel, out_channel, stride=1)\n",
    "        self.bn3 = _bn_last(out_channel)\n",
    "\n",
    "        # Relu 激活层\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.down_sample = False\n",
    "\n",
    "        # 当步长不为1、或输出通道不等于输入通道时，进行图像下采样，用来调整通道数\n",
    "        if stride != 1 or in_channel != out_channel:\n",
    "            self.down_sample = True\n",
    "        self.downsample_layer = None\n",
    "        # 用 1x1 卷积调整通道数\n",
    "        if self.down_sample:\n",
    "            self.downsample_layer = nn.SequentialCell(\n",
    "                [_conv1x1(in_channel, out_channel, stride), _bn(out_channel)]\n",
    "            )\n",
    "\n",
    "        # 加法算子\n",
    "        self.add = ops.Add()\n",
    "\n",
    "    # 构建残差块\n",
    "    def construct(self, x):\n",
    "        # 输入\n",
    "        identity = x\n",
    "\n",
    "        # 第一层卷积 1X1\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        # 第二层卷积 3X3\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        # 第三层卷积 1X1\n",
    "        out = self.conv3(x)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        # 改变网络的维度\n",
    "        if self.down_sample:\n",
    "            identity = self.downsample_layer(identity)\n",
    "\n",
    "        # 加上残差\n",
    "        out = self.add(out, identity)\n",
    "        # Relu 激活\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "# 构建残差网络\n",
    "class ResNet(nn.Cell):\n",
    "    # 输入参数为：残差块，残差块重复数，输入通道，输出通道，步长，图像类别数\n",
    "    def __init__(\n",
    "        self, block, layer_nums, in_channels, out_channels, strides, num_classes\n",
    "    ):\n",
    "        super(ResNet, self).__init__()\n",
    "        if not len(layer_nums) == len(out_channels) == len(strides) == 4:\n",
    "            raise ValueError(\"the length of layer_num, out_channel, stride must be 4!\")\n",
    "\n",
    "        # 第一层卷积，卷积核 7X7，输入通道3，输出通道64，步长2\n",
    "        self.conv1 = _conv7x7(3, 64, stride=2)\n",
    "        self.bn1 = _bn(64)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # 最大池化层，核大小 3X3，步长 2\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, pad_mode=\"same\")\n",
    "\n",
    "        # conv2_x 残差块\n",
    "        self.layer1 = self._make_layer(\n",
    "            block,\n",
    "            layer_nums[0],\n",
    "            in_channel=in_channels[0],\n",
    "            out_channel=out_channels[0],\n",
    "            stride=strides[0],\n",
    "        )\n",
    "\n",
    "        # conv3_x 残差块\n",
    "        self.layer2 = self._make_layer(\n",
    "            block,\n",
    "            layer_nums[1],\n",
    "            in_channel=in_channels[1],\n",
    "            out_channel=out_channels[1],\n",
    "            stride=strides[1],\n",
    "        )\n",
    "\n",
    "        # conv4_x 残差块\n",
    "        self.layer3 = self._make_layer(\n",
    "            block,\n",
    "            layer_nums[2],\n",
    "            in_channel=in_channels[2],\n",
    "            out_channel=out_channels[2],\n",
    "            stride=strides[2],\n",
    "        )\n",
    "\n",
    "        # conv5_x 残差块\n",
    "        self.layer4 = self._make_layer(\n",
    "            block,\n",
    "            layer_nums[3],\n",
    "            in_channel=in_channels[3],\n",
    "            out_channel=out_channels[3],\n",
    "            stride=strides[3],\n",
    "        )\n",
    "\n",
    "        # 均值算子\n",
    "        self.mean = ops.ReduceMean(keep_dims=True)\n",
    "        # Flatten 层\n",
    "        self.flatten = nn.Flatten()\n",
    "        # 输出层\n",
    "        self.end_point = _fc(out_channels[3], num_classes)\n",
    "\n",
    "    # 输出参数为：残差块，残差块重复数，输入通道，输出通道，步长\n",
    "    def _make_layer(self, block, layer_num, in_channel, out_channel, stride):\n",
    "        layers = []\n",
    "        # 第一个残差块可能改变维度，所以单独构建\n",
    "        resnet_block = block(in_channel, out_channel, stride=stride)\n",
    "        layers.append(resnet_block)\n",
    "\n",
    "        for _ in range(1, layer_num):\n",
    "            # 其他残差块维持不变\n",
    "            resnet_block = block(out_channel, out_channel, stride=1)\n",
    "            layers.append(resnet_block)\n",
    "\n",
    "        return nn.SequentialCell(layers)\n",
    "\n",
    "    # 构建 ResNet 网络\n",
    "    def construct(self, x):\n",
    "        # 第一层卷积\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        c1 = self.maxpool(x)\n",
    "\n",
    "        c2 = self.layer1(c1)  # conv2_x 残差块\n",
    "        c3 = self.layer2(c2)  # conv3_x 残差块\n",
    "        c4 = self.layer3(c3)  # conv4_x 残差块\n",
    "        c5 = self.layer4(c4)  # conv5_x 残差块\n",
    "\n",
    "        out = self.mean(c5, (2, 3))  # 平均池化层\n",
    "        out = self.flatten(out)  # Flatten 层\n",
    "        out = self.end_point(out)  # 输出层\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "# 构建 ResNet50 网络\n",
    "def resnet50(class_num=5):\n",
    "    return ResNet(\n",
    "        ResidualBlock,  # 残差块\n",
    "        [3, 4, 6, 3],  # 残差块重复数\n",
    "        [64, 256, 512, 1024],  # 输入通道\n",
    "        [256, 512, 1024, 2048],  # 输出通道\n",
    "        [1, 2, 2, 2],  # 步长\n",
    "        class_num,  # 图像类别数\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建 ResNet50 网络，输出类别数为5，对应5种花的类别\n",
    "net = resnet50(class_num=cfg.num_class)\n",
    "\n",
    "# 读取预训练模型参数\n",
    "param_dict = load_checkpoint(\n",
    "    \"model_resnet/resnet50_ascend_v170_imagenet2012_official_cv_top1acc76.97_top5acc93.44.ckpt\"\n",
    ")\n",
    "\n",
    "# 展示读取的模型参数\n",
    "print(param_dict)\n",
    "\n",
    "# 通过 mindspore.Parameter() 修改 end_point.weight 和 end_point.bias 对应的 shape\n",
    "param_dict[\"end_point.weight\"] = mindspore.Parameter(\n",
    "    Tensor(param_dict[\"end_point.weight\"][:5, :], mindspore.float32), name=\"variable\"\n",
    ")\n",
    "param_dict[\"end_point.bias\"] = mindspore.Parameter(\n",
    "    Tensor(param_dict[\"end_point.bias\"][:5], mindspore.float32), name=\"variable\"\n",
    ")\n",
    "\n",
    "# 设置 Softmax 交叉熵损失函数\n",
    "loss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\n",
    "\n",
    "# 设置学习率\n",
    "train_step_size = de_train.get_dataset_size()  # 训练集大小\n",
    "lr = nn.cosine_decay_lr(\n",
    "    min_lr=0.0001,\n",
    "    max_lr=0.001,\n",
    "    total_step=train_step_size * cfg.epoch_size,\n",
    "    step_per_epoch=train_step_size,\n",
    "    decay_epoch=cfg.epoch_size,\n",
    ")\n",
    "\n",
    "# 设置动量优化器\n",
    "opt = Momentum(\n",
    "    net.trainable_params(),\n",
    "    lr,\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-4,\n",
    "    loss_scale=cfg.loss_scale_num,\n",
    ")\n",
    "\n",
    "# 损失值平滑，解决训练过程中梯度过小的问题\n",
    "loss_scale = FixedLossScaleManager(cfg.loss_scale_num, False)\n",
    "\n",
    "# 模型编译，输入网络结构，损失函数，优化器，损失值平滑，以及模型评估标准\n",
    "model = Model(\n",
    "    net, loss_fn=loss, optimizer=opt, loss_scale_manager=loss_scale, metrics={\"acc\"}\n",
    ")\n",
    "\n",
    "# 损失值监控\n",
    "loss_cb = LossMonitor(per_print_times=train_step_size)\n",
    "\n",
    "# 模型保存参数，设置每隔多少步保存一次模型，最多保存几个模型\n",
    "ckpt_config = CheckpointConfig(\n",
    "    save_checkpoint_steps=cfg.save_checkpoint_steps, keep_checkpoint_max=1\n",
    ")\n",
    "\n",
    "# 模型保存，设置模型保存的名称，路径，以及保存参数\n",
    "ckpoint_cb = ModelCheckpoint(\n",
    "    prefix=cfg.prefix, directory=cfg.directory, config=ckpt_config\n",
    ")\n",
    "\n",
    "print(\"============== Starting Training ==============\")\n",
    "# 训练模型，设置训练次数，训练集，回调函数，是否采用数据下沉模式（只能应用于 Ascend 和 GPU）\n",
    "model.train(\n",
    "    cfg.epoch_size, de_train, callbacks=[loss_cb, ckpoint_cb], dataset_sink_mode=True\n",
    ")\n",
    "# 训练时长 15-20 分钟\n",
    "\n",
    "# 使用测试集进行模型评估，输出测试集的准确率\n",
    "metric = model.eval(de_test)\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测，从测试集中取10个样本进行测试，输出预测结果和真实结果\n",
    "class_names = {0: \"daisy\", 1: \"dandelion\", 2: \"roses\", 3: \"sunflowers\", 4: \"tulips\"}\n",
    "for i in range(10):\n",
    "    test_ = de_test.create_dict_iterator().__next__()\n",
    "    test = Tensor(test_[\"image\"], mindspore.float32)\n",
    "    # 模型预测\n",
    "    predictions = model.predict(test)\n",
    "    predictions = predictions.asnumpy()\n",
    "    true_label = test_[\"label\"].asnumpy()\n",
    "    # 显示预测结果\n",
    "    p_np = predictions[0, :]\n",
    "    pred_label = np.argmax(p_np)\n",
    "    print(\n",
    "        \"第\"\n",
    "        + str(i)\n",
    "        + \"个样本的预测结果为：\"\n",
    "        + class_names[pred_label]\n",
    "        + \"，真实结果为：\"\n",
    "        + class_names[true_label]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8",
   "language": "python",
   "name": "pytorch-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
